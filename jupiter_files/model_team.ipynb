{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\kelvi\\AppData\\Local\\Temp\\ipykernel_15464\\3255635602.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  df = pd.read_csv('dataset_fifa\\players_22.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         BMI  stamina_score  injury_risk  training_intensity  recovery_time\n",
      "0  24.913495      73.666667          5.0           25.833333      22.000000\n",
      "1  23.666910      80.333333          6.5           27.500000      15.333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelvi\\AppData\\Local\\Temp\\ipykernel_15464\\3255635602.py:1: DtypeWarning: Columns (25,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('dataset_fifa\\players_22.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_fifa\\players_22.csv')\n",
    "\n",
    "work_rate_mapping = {\n",
    "    'Low': 1,\n",
    "    'Medium': 2,\n",
    "    'High': 3\n",
    "}\n",
    "\n",
    "# Function to convert work_rate into numerical score\n",
    "def work_rate_to_numeric(work_rate):\n",
    "    offensive, defensive = work_rate.split('/')\n",
    "    return (work_rate_mapping[offensive.strip()] + work_rate_mapping[defensive.strip()]) / 2\n",
    "\n",
    "# Apply the function to the 'work_rate' column\n",
    "df['work_rate_numeric'] = df['work_rate'].apply(work_rate_to_numeric)\n",
    "\n",
    "# Calculate BMI\n",
    "df['BMI'] = df['weight_kg'] / (df['height_cm'] / 100) ** 2\n",
    "\n",
    "# Stamina Score (combining power_stamina, movement_sprint_speed, and power_strength)\n",
    "df['stamina_score'] = (df['power_stamina'] + df['movement_sprint_speed'] + df['power_strength']) / 3\n",
    "\n",
    "# Injury Risk (based on mentality_aggression, power_strength, and physic)\n",
    "df['injury_risk'] = ((df['mentality_aggression'] - df['power_strength']) + (100 - df['physic'])) / 2\n",
    "\n",
    "# Training Intensity (based on skill_moves, work_rate_numeric, and power_stamina)\n",
    "df['training_intensity'] = (df['skill_moves'] + df['work_rate_numeric'] + df['power_stamina']) / 3\n",
    "\n",
    "# Recovery Time (based on power_stamina, power_jumping, and movement_reactions)\n",
    "df['recovery_time'] = 100 - (df['power_stamina'] + df['power_jumping'] + df['movement_reactions']) / 3\n",
    "\n",
    "# Display the computed values\n",
    "print(df[['BMI', 'stamina_score', 'injury_risk', 'training_intensity', 'recovery_time']].head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming df is your existing dataframe\n",
    "\n",
    "# Step 1: Renaming the relevant columns\n",
    "df.rename(columns={\n",
    "    'age': 'Player_Age',\n",
    "    'weight_kg': 'Player_Weight',\n",
    "    'height_cm': 'Player_Height',\n",
    "    'Previous_Injuries': 'Previous_Injuries',\n",
    "    'training_intensity': 'Training_Intensity',\n",
    "    'recovery_time': 'Recovery_Time',\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 2: Classifying BMI\n",
    "# Defining the gaps for BMI classification\n",
    "gaps = [-float('inf'), 18.5, 24.9, 29.9, 34.9, 39.9, float('inf')]\n",
    "categories = ['Underweight', 'Normal', 'Overweight', 'Obesity I', 'Obesity II', 'Obesity III']\n",
    "\n",
    "# Create \"BMI_Classification\" column\n",
    "df['BMI_Classification'] = pd.cut(df['BMI'], bins=gaps, labels=categories, right=False)\n",
    "\n",
    "# Step 3: Adding age groups\n",
    "df[\"Age_Group\"] = pd.cut(\n",
    "    df[\"Player_Age\"],\n",
    "    bins=[18, 22, 26, 30, 34, df[\"Player_Age\"].max()],\n",
    "    labels=[\"18-22\", \"23-26\", \"27-30\", \"31-34\", \"35+\"],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Step 4: One-hot encoding for 'BMI_Classification' and 'Age_Group'\n",
    "one_hot_cols = [\"BMI_Classification\", \"Age_Group\"]\n",
    "\n",
    "# Selecting only categorical columns\n",
    "df_categorical = df[one_hot_cols]\n",
    "\n",
    "# Applying OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(df_categorical)\n",
    "\n",
    "# Obtaining names of the features generated by OneHotEncoder\n",
    "one_hot_feature_names = encoder.get_feature_names_out(one_hot_cols)\n",
    "df_encoded = pd.DataFrame(encoded_data.toarray(), columns=one_hot_feature_names)\n",
    "\n",
    "# Step 5: Joining the encoded columns back into the original DataFrame\n",
    "df_final = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Step 6: Ensuring all required columns are present, even if some categories are missing\n",
    "required_columns = [\n",
    "    'Player_Age', 'Player_Weight', 'Player_Height', 'Previous_Injuries',\n",
    "    'Training_Intensity', 'Recovery_Time', 'BMI_Classification_Normal',\n",
    "    'BMI_Classification_Obesity I', 'BMI_Classification_Obesity II',\n",
    "    'BMI_Classification_Overweight', 'BMI_Classification_Underweight'\n",
    "]\n",
    "\n",
    "# If a column is missing, add it and fill with zeros\n",
    "for col in required_columns:\n",
    "    if col not in df_final.columns:\n",
    "        df_final[col] = np.zeros(len(df_final))\n",
    "\n",
    "# Step 7: Selecting the final columns in the order you specified\n",
    "df_final = df_final[required_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['player_positions'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', \n",
    "                   'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', \n",
    "                   'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk', 'player_face_url', 'club_logo_url', \n",
    "                   'club_flag_url', 'nation_logo_url', 'nation_flag_url']\n",
    "\n",
    "# Drop the columns from the DataFrame\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the DataFrame to verify the columns have been removed\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sofifa_id', 'short_name', 'player_positions', 'overall', 'potential',\n",
       "       'value_eur', 'wage_eur', 'Player_Age', 'dob', 'Player_Height',\n",
       "       'Player_Weight', 'nation_team_id', 'nation_position',\n",
       "       'nation_jersey_number', 'preferred_foot', 'weak_foot', 'skill_moves',\n",
       "       'international_reputation', 'work_rate', 'body_type', 'real_face',\n",
       "       'release_clause_eur', 'player_tags', 'player_traits', 'pace',\n",
       "       'shooting', 'passing', 'dribbling', 'defending', 'physic',\n",
       "       'attacking_crossing', 'attacking_finishing',\n",
       "       'attacking_heading_accuracy', 'attacking_short_passing',\n",
       "       'attacking_volleys', 'skill_dribbling', 'skill_curve',\n",
       "       'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',\n",
       "       'movement_acceleration', 'movement_sprint_speed', 'movement_agility',\n",
       "       'movement_reactions', 'movement_balance', 'power_shot_power',\n",
       "       'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots',\n",
       "       'mentality_aggression', 'mentality_interceptions',\n",
       "       'mentality_positioning', 'mentality_vision', 'mentality_penalties',\n",
       "       'mentality_composure', 'defending_marking_awareness',\n",
       "       'defending_standing_tackle', 'defending_sliding_tackle',\n",
       "       'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking',\n",
       "       'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed',\n",
       "       'work_rate_numeric', 'BMI', 'stamina_score', 'injury_risk',\n",
       "       'Training_Intensity', 'Recovery_Time', 'BMI_Classification',\n",
       "       'Age_Group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['club_team_id',\n",
    "       'club_name', 'league_name', 'league_level', 'club_position',\n",
    "       'club_jersey_number', 'club_loaned_from', 'club_joined',\n",
    "       'club_contract_valid_until', 'nationality_id', 'nationality_name', 'long_name','player_url',])\n",
    "df.columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sofifa_id', 'short_name', 'player_positions', 'overall', 'potential',\n",
       "       'value_eur', 'wage_eur', 'Player_Age', 'dob', 'Player_Height',\n",
       "       'Player_Weight', 'nation_team_id', 'nation_position',\n",
       "       'nation_jersey_number', 'preferred_foot', 'weak_foot', 'skill_moves',\n",
       "       'international_reputation', 'work_rate', 'body_type', 'real_face',\n",
       "       'release_clause_eur', 'player_tags', 'player_traits', 'pace',\n",
       "       'shooting', 'passing', 'dribbling', 'defending', 'physic',\n",
       "       'attacking_crossing', 'attacking_finishing',\n",
       "       'attacking_heading_accuracy', 'attacking_short_passing',\n",
       "       'attacking_volleys', 'skill_dribbling', 'skill_curve',\n",
       "       'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',\n",
       "       'movement_acceleration', 'movement_sprint_speed', 'movement_agility',\n",
       "       'movement_reactions', 'movement_balance', 'power_shot_power',\n",
       "       'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots',\n",
       "       'mentality_aggression', 'mentality_interceptions',\n",
       "       'mentality_positioning', 'mentality_vision', 'mentality_penalties',\n",
       "       'mentality_composure', 'defending_marking_awareness',\n",
       "       'defending_standing_tackle', 'defending_sliding_tackle',\n",
       "       'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking',\n",
       "       'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed',\n",
       "       'work_rate_numeric', 'BMI', 'stamina_score', 'injury_risk',\n",
       "       'Training_Intensity', 'Recovery_Time', 'BMI_Classification',\n",
       "       'Age_Group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "attributes = ['pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic', 'overall', 'Player_Age', 'Player_Height', 'Player_Weight','BMI', 'stamina_score', 'injury_risk', 'Training_Intensity', 'Recovery_Time']\n",
    "\n",
    "\n",
    "# Function to create balanced teams with proper player composition\n",
    "team_composition = {\n",
    "    'GK': 1,  # Goalkeeper\n",
    "    'CB': 2,  # Center Backs\n",
    "    'LB': 1,  # Left Back\n",
    "    'RB': 1,  # Right Back\n",
    "    'CDM': 1, # Central Defensive Midfielder\n",
    "    'CM': 2,  # Central Midfielders\n",
    "    'CAM': 1, # Central Attacking Midfielder\n",
    "    'LW': 1,  # Left Winger\n",
    "    'RW': 1,  # Right Winger\n",
    "    'ST': 1   # Striker\n",
    "}\n",
    "\n",
    "def create_balanced_teams(df):\n",
    "    team_a_players = pd.DataFrame()\n",
    "    team_b_players = pd.DataFrame()\n",
    "\n",
    "    # Make a copy of the DataFrame to keep track of remaining available players\n",
    "    available_players = df.copy()\n",
    "\n",
    "    for position, num_players in team_composition.items():\n",
    "        # Filter available players by position\n",
    "        players_in_position = available_players[available_players['player_positions'].apply(lambda x: position in x)]\n",
    "\n",
    "        if len(players_in_position) < 2 * num_players:\n",
    "            raise ValueError(f\"Not enough players available for position: {position}\")\n",
    "        \n",
    "        # Randomly select 'num_players' players for Team A based on 'sofifa_id'\n",
    "        team_a_position_players = players_in_position.sample(num_players, random_state=1).reset_index(drop=True)\n",
    "\n",
    "        # Remove the selected Team A players from the available pool using 'sofifa_id'\n",
    "        available_players = available_players[~available_players['sofifa_id'].isin(team_a_position_players['sofifa_id'])]\n",
    "\n",
    "        # Filter remaining players for Team B\n",
    "        players_in_position_for_b = available_players[available_players['player_positions'].apply(lambda x: position in x)]\n",
    "        team_b_position_players = players_in_position_for_b.sample(num_players, random_state=1).reset_index(drop=True)\n",
    "\n",
    "        # Append players to Team A and Team B\n",
    "        team_a_players = pd.concat([team_a_players, team_a_position_players], ignore_index=True)\n",
    "        team_b_players = pd.concat([team_b_players, team_b_position_players], ignore_index=True)\n",
    "\n",
    "    return team_a_players, team_b_players\n",
    "\n",
    "# Example function to compare two players based on their statistics\n",
    "def compare_players(player_a, player_b, player_position):\n",
    "    # Define stats based on position categories\n",
    "    position_stats = {\n",
    "    'GK': ['goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_reflexes', 'goalkeeping_positioning'],\n",
    "    'DF': ['defending_marking_awareness', 'defending_standing_tackle', 'mentality_interceptions', 'physic'],\n",
    "    'MF': ['passing', 'dribbling', 'attacking_short_passing', 'mentality_vision'],\n",
    "    'FW': ['shooting', 'dribbling', 'attacking_finishing'],\n",
    "    'General': ['overall', 'potential', 'work_rate_numeric', 'stamina_score', 'injury_risk']\n",
    "}\n",
    "\n",
    "\n",
    "    # Select relevant stats based on player position\n",
    "    if player_position == 'GK':\n",
    "        stats_to_compare = position_stats['GK'] + position_stats['General']\n",
    "    elif player_position in ['DF', 'LB', 'RB', 'CB']:\n",
    "        stats_to_compare = position_stats['DF'] + position_stats['General']\n",
    "    elif player_position in ['MF', 'CM', 'CDM', 'CAM']:\n",
    "        stats_to_compare = position_stats['MF'] + position_stats['General']\n",
    "    elif player_position in ['FW', 'ST', 'LW', 'RW']:\n",
    "        stats_to_compare = position_stats['FW'] + position_stats['General']\n",
    "    else:\n",
    "        # In case of an unrecognized position, use general stats only\n",
    "        stats_to_compare = position_stats['General']\n",
    "    \n",
    "    # Initialize comparison scores\n",
    "    player_a_score = 0\n",
    "    player_b_score = 0\n",
    "    \n",
    "    # Compare each stat\n",
    "    for stat in stats_to_compare:\n",
    "        if player_a[stat] > player_b[stat]:\n",
    "            player_a_score += 1\n",
    "        elif player_b[stat] > player_a[stat]:\n",
    "            player_b_score += 1\n",
    "\n",
    "    # Return the result for the position\n",
    "    if player_a_score > player_b_score:\n",
    "        return 1  # Player A wins\n",
    "    elif player_b_score > player_a_score:\n",
    "        return -1  # Player B wins\n",
    "    else:\n",
    "        return 0  # Draw\n",
    "\n",
    "\n",
    "# Function to evaluate team performance based on player comparison\n",
    "def evaluate_team_performance(team_a, team_b):\n",
    "    total_score = 0\n",
    "\n",
    "    # Loop through each position and compare corresponding players\n",
    "    for i in range(11):\n",
    "        player_a = team_a.iloc[i]\n",
    "        player_b = team_b.iloc[i]\n",
    "        position = player_a['player_positions']  # Assuming both teams have players in the same order of positions\n",
    "\n",
    "        # Compare the players for the given position\n",
    "        result = compare_players(player_a, player_b, position)\n",
    "\n",
    "        # Add the result to the total score\n",
    "        total_score += result\n",
    "\n",
    "    # Determine the winning team based on the total score\n",
    "    if total_score > 0:\n",
    "        return \"Team A wins\"  # Team A wins if score is positive\n",
    "    elif total_score < 0:\n",
    "        return \"Team B wins\"  # Team B wins if score is negative\n",
    "    else:\n",
    "        return \"It's a draw\"  # Draw if the score is zero\n",
    "\n",
    "def aggregate_team_stats(team_players):\n",
    "    return team_players[attributes].mean()\n",
    "# Main function to generate match data\n",
    "def generate_match_data(df, num_matches=3000):\n",
    "    match_data = []\n",
    "    match_labels = []\n",
    "    unique_team_compositions = set()  # Store unique team compositions\n",
    "    \n",
    "    while len(match_data) < num_matches:\n",
    "        # Create balanced teams based on positions\n",
    "        team_a_players, team_b_players = create_balanced_teams(df)\n",
    "        \n",
    "        # Sort `sofifa_id`s to ensure that Team A and Team B are uniquely identified\n",
    "        team_a_ids = tuple(sorted(team_a_players['sofifa_id'].tolist()))\n",
    "        team_b_ids = tuple(sorted(team_b_players['sofifa_id'].tolist()))\n",
    "        \n",
    "        # Create a unique identifier for the match by combining Team A and Team B's IDs\n",
    "        match_identifier = (team_a_ids, team_b_ids)\n",
    "        \n",
    "        # Check if the team composition has been seen before\n",
    "        if match_identifier in unique_team_compositions:\n",
    "            continue  # Skip and regenerate new teams if the composition is repeated\n",
    "        \n",
    "        # If it's a new combination, add it to the set\n",
    "        unique_team_compositions.add(match_identifier)\n",
    "        \n",
    "        # Aggregate key player statistics for both teams\n",
    "        team_a_stats = aggregate_team_stats(team_a_players).add_suffix('_a')\n",
    "        team_b_stats = aggregate_team_stats(team_b_players).add_suffix('_b')\n",
    "        \n",
    "        # Combine both teams' stats into a single row for match features\n",
    "        match_features = pd.concat([team_a_stats, team_b_stats], axis=0)\n",
    "        \n",
    "        # Predict the winner based on player composition, balance, and player-to-player mapping\n",
    "        winner = evaluate_team_performance(team_a_players, team_b_players)\n",
    "        \n",
    "        # Append to match data and labels\n",
    "        match_data.append(match_features)\n",
    "        match_labels.append(winner)\n",
    "    \n",
    "    return pd.DataFrame(match_data), match_labels\n",
    "\n",
    "\n",
    "def generate_mvp_data(df):\n",
    "    mvp_data = []\n",
    "    mvp_labels = []\n",
    "    \n",
    "    # Attributes considered for MVP selection\n",
    "    mvp_attributes = ['overall', 'shooting', 'passing', 'dribbling', 'attacking_finishing', \n",
    "                      'skill_dribbling', 'physic', 'stamina_score', 'Training_Intensity']\n",
    "    \n",
    "    # Verify which columns exist in the DataFrame\n",
    "    available_attributes = [attr for attr in mvp_attributes if attr in df.columns]\n",
    "    missing_attributes = [attr for attr in mvp_attributes if attr not in df.columns]\n",
    "\n",
    "    # Notify if some required attributes are missing\n",
    "    if missing_attributes:\n",
    "        print(f\"Warning: The following attributes are missing in the DataFrame: {missing_attributes}\")\n",
    "    \n",
    "    # Iterate over the matches/players to gather stats and identify MVP\n",
    "    for _, match in df.iterrows():\n",
    "        # Extract the stats based on available attributes\n",
    "        players_stats = match[available_attributes]\n",
    "        \n",
    "        # Normalize the stats (optional step based on importance of attributes)\n",
    "        players_stats_normalized = (players_stats - players_stats.min()) / (players_stats.max() - players_stats.min())\n",
    "        \n",
    "        # Calculate a score based on normalized stats\n",
    "        score = players_stats_normalized.mean()\n",
    "        \n",
    "        # MVP selection: The player with the highest score becomes MVP\n",
    "        mvp = np.argmax(score)\n",
    "        \n",
    "        mvp_data.append(players_stats.tolist())  # Append the player stats\n",
    "        mvp_labels.append(mvp)  # Append the calculated MVP label\n",
    "\n",
    "    # Return a DataFrame of player stats and a list of MVP labels\n",
    "    return pd.DataFrame(mvp_data, columns=available_attributes), mvp_labels\n",
    "\n",
    "# Define offensive and defensive stats for goal prediction\n",
    "offensive_stats = ['shooting', 'attacking_finishing', 'passing', 'dribbling']\n",
    "defensive_stats = ['defending', 'physic', 'goalkeeping_diving', 'goalkeeping_positioning', 'goalkeeping_reflexes']\n",
    "\n",
    "def goal_probability(offensive_score, defensive_score):\n",
    "    # Example formula: Use the difference between offensive and defensive score to predict goals\n",
    "    # This can be adjusted with weights or more complex models\n",
    "    score_diff = offensive_score - defensive_score\n",
    "    goal_prob = max(0, score_diff / 50)  # Normalize score difference to a goal probability range\n",
    "    return np.clip(np.round(goal_prob), 0, 4)  # Max 4 goals per match for simplicity\n",
    "\n",
    "def generate_goal_data(df, num_matches=3000):\n",
    "    match_data = []\n",
    "    goal_labels = []\n",
    "    \n",
    "    for _ in range(num_matches):\n",
    "        # Randomly select 11 players for Team A and Team B\n",
    "        team_a_players, team_b_players = create_balanced_teams(df)\n",
    "        \n",
    "        # Aggregate key player statistics for both teams\n",
    "        team_a_offensive_stats = team_a_players[offensive_stats].mean().sum()  # Aggregate offensive stats for Team A\n",
    "        team_a_defensive_stats = team_a_players[defensive_stats].mean().sum()  # Aggregate defensive stats for Team A\n",
    "        \n",
    "        team_b_offensive_stats = team_b_players[offensive_stats].mean().sum()  # Aggregate offensive stats for Team B\n",
    "        team_b_defensive_stats = team_b_players[defensive_stats].mean().sum()  # Aggregate defensive stats for Team B\n",
    "        \n",
    "        # Predict goals based on offensive and defensive stats\n",
    "        goals_team_a = goal_probability(team_a_offensive_stats, team_b_defensive_stats)\n",
    "        goals_team_b = goal_probability(team_b_offensive_stats, team_a_defensive_stats)\n",
    "        \n",
    "        # Prepare feature set for the match (team stats combined)\n",
    "        team_a_stats = aggregate_team_stats(team_a_players).add_suffix('_a')\n",
    "        team_b_stats = aggregate_team_stats(team_b_players).add_suffix('_b')\n",
    "        match_features = pd.concat([team_a_stats, team_b_stats], axis=0)\n",
    "        \n",
    "        # Append the match data and the goal labels\n",
    "        match_data.append(match_features)\n",
    "        goal_labels.append([goals_team_a, goals_team_b])\n",
    "    \n",
    "    # Return a DataFrame with match data and corresponding goal labels\n",
    "    return pd.DataFrame(match_data), goal_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_match_data(df, num_matches=3000, max_attempts=10000):\n",
    "    match_data = []\n",
    "    match_labels = []\n",
    "    unique_team_compositions = set()  # Store unique team compositions\n",
    "    attempts = 0  # To track how many times we have attempted to create a unique match\n",
    "    \n",
    "    while len(match_data) < num_matches and attempts < max_attempts:\n",
    "        # Create balanced teams based on positions\n",
    "        team_a_players, team_b_players = create_balanced_teams(df)\n",
    "        \n",
    "        # Sort `sofifa_id`s to ensure that Team A and Team B are uniquely identified\n",
    "        team_a_ids = tuple(sorted(team_a_players['sofifa_id'].tolist()))\n",
    "        team_b_ids = tuple(sorted(team_b_players['sofifa_id'].tolist()))\n",
    "        \n",
    "        # Create a unique identifier for the match by combining Team A and Team B's IDs\n",
    "        match_identifier = (team_a_ids, team_b_ids)\n",
    "        \n",
    "        # Check if the team composition has been seen before\n",
    "        if match_identifier in unique_team_compositions:\n",
    "            attempts += 1  # Increment attempts for trying to create unique teams\n",
    "            continue  # Skip and regenerate new teams if the composition is repeated\n",
    "        \n",
    "        # If it's a new combination, add it to the set\n",
    "        unique_team_compositions.add(match_identifier)\n",
    "        \n",
    "        # Aggregate key player statistics for both teams\n",
    "        team_a_stats = aggregate_team_stats(team_a_players).add_suffix('_a')\n",
    "        team_b_stats = aggregate_team_stats(team_b_players).add_suffix('_b')\n",
    "        \n",
    "        # Combine both teams' stats into a single row for match features\n",
    "        match_features = pd.concat([team_a_stats, team_b_stats], axis=0)\n",
    "        \n",
    "        # Predict the winner based on player composition, balance, and player-to-player mapping\n",
    "        winner = evaluate_team_performance(team_a_players, team_b_players)\n",
    "        \n",
    "        # Append to match data and labels\n",
    "        match_data.append(match_features)\n",
    "        match_labels.append(winner)\n",
    "        \n",
    "        # Reset attempts since we successfully created a match\n",
    "        attempts = 0\n",
    "    \n",
    "    if len(match_data) < num_matches:\n",
    "        print(f\"Warning: Only generated {len(match_data)} unique matches after {max_attempts} attempts.\")\n",
    "    \n",
    "    return pd.DataFrame(match_data), match_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# df should be your DataFrame containing player data\n",
    "# team_a, team_b = create_balanced_teams(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only generated 1 unique matches after 10000 attempts.\n"
     ]
    }
   ],
   "source": [
    "# team_a_players, team_b_players = create_balanced_teams(df)\n",
    "# team_a_stats = aggregate_team_stats(team_a_players).add_suffix('_a')\n",
    "# team_b_stats = aggregate_team_stats(team_b_players).add_suffix('_b')\n",
    "# winner = evaluate_team_performance(team_a_players, team_b_players)\n",
    "X, y = generate_match_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Key player attributes for model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train a Random Forest classifier\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Key player attributes for model\n",
    "# Train a Random Forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# model=models['AdaBoostClassifier']\n",
    "model_filename = 'teammodel.pkl'\n",
    "joblib.dump(model, model_filename)\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted MVP: [0 0 0 ... 0 0 0]\n",
      "Warning: The following attributes are missing in the DataFrame: ['age']\n",
      "Injury Likelihood Prediction: [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming df is already loaded\n",
    "X_mvp, y_mvp = generate_mvp_data(df)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_mvp, X_test_mvp, y_train_mvp, y_test_mvp = train_test_split(X_mvp, y_mvp, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the MVP prediction model\n",
    "mvp_model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "mvp_model.fit(X_trai`n_mvp, y_train_mvp)\n",
    "\n",
    "# Predict MVP from team selection\n",
    "mvp_prediction = mvp_model.predict(X_test_mvp)\n",
    "print(f\"Predicted MVP: {mvp_prediction}\")\n",
    "# List of attributes used for injury prediction\n",
    "# injury_attributes = ['age', 'strength', 'power_jumping', 'sprint_speed','stamina']\n",
    "injury_attributes = ['age', 'power_jumping']\n",
    "# Train Injury model (assuming historical injury data is available)\n",
    "def generate_injury_data(df):\n",
    "    injury_data = []\n",
    "    injury_labels = []\n",
    "    \n",
    "    # Verify which columns exist in the DataFrame\n",
    "    available_attributes = [attr for attr in injury_attributes if attr in df.columns]\n",
    "    missing_attributes = [attr for attr in injury_attributes if attr not in df.columns]\n",
    "\n",
    "    if missing_attributes:\n",
    "        print(f\"Warning: The following attributes are missing in the DataFrame: {missing_attributes}\")\n",
    "    \n",
    "    # Iterate over players to gather injury risk stats\n",
    "    for _, player in df.iterrows():\n",
    "        player_stats = player[available_attributes]  # Only use available attributes\n",
    "        injury = np.random.choice([0, 1], p=[0.85, 0.15])  # Assume 15% injury likelihood\n",
    "        \n",
    "        injury_data.append(player_stats)\n",
    "        injury_labels.append(injury)\n",
    "\n",
    "    return pd.DataFrame(injury_data), injury_labels\n",
    "\n",
    "# Assuming df is already loaded\n",
    "X_injury, y_injury = generate_injury_data(df)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_injury, X_test_injury, y_train_injury, y_test_injury = train_test_split(X_injury, y_injury, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the injury prediction model\n",
    "injury_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "injury_model.fit(X_train_injury, y_train_injury)\n",
    "\n",
    "# Predict Injury likelihood\n",
    "injury_prediction = injury_model.predict(X_test_injury)\n",
    "print(f\"Injury Likelihood Prediction: {injury_prediction}\")\n",
    "\n",
    "\n",
    "\n",
    "# Generate match data with goals\n",
    "X_goals, y_goals = generate_goal_data(df)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train_goals, X_test_goals, y_train_goals, y_test_goals = train_test_split(X_goals, y_goals, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Regressor to predict goals\n",
    "goal_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "goal_model.fit(X_train_goals, [goals[0] for goals in y_train_goals])  # Train on goals for Team A (or Team B)\n",
    "\n",
    "# Assume user has selected 11 players for each team\n",
    "team_a_players = df[df['sofifa_id'].isin(list(df['sofifa_id'].sample(11)))]  # Replace with actual IDs\n",
    "team_b_players = df[df['sofifa_id'].isin(list(df['sofifa_id'].sample(11)))]  # Replace with actual IDs\n",
    "\n",
    "# Aggregate stats for both teams\n",
    "team_a_stats = aggregate_team_stats(team_a_players).add_suffix('_a')\n",
    "team_b_stats = aggregate_team_stats(team_b_players).add_suffix('_b')\n",
    "\n",
    "# Combine both teams' stats into a single row\n",
    "match_features = pd.concat([team_a_stats, team_b_stats], axis=0).to_frame().T\n",
    "# Team Dominance Prediction\n",
    "# Predict which team will dominate\n",
    "team_dominance = model.predict(match_features)\n",
    "\n",
    "if team_dominance == 0:\n",
    "    dominant_team = 'Team A'\n",
    "    dominant_team_players = team_a_players\n",
    "    dominant_team_stats = team_a_stats\n",
    "else:\n",
    "    dominant_team = 'Team B'\n",
    "    dominant_team_players = team_b_players\n",
    "    dominant_team_stats = team_b_stats\n",
    "\n",
    "print(f\"{dominant_team} is predicted to dominate!\")\n",
    "\n",
    "# MVP Prediction for the dominant team\n",
    "mvp_attributes = ['overall', 'shooting', 'passing', 'dribbling', 'attacking_finishing', \n",
    "                      'skill_dribbling', 'physic', 'stamina_score', 'Training_Intensity']\n",
    "# Ensure that only available MVP attributes are used\n",
    "available_mvp_attributes = [attr for attr in mvp_attributes if attr in dominant_team_players.columns]\n",
    "\n",
    "# Check if all necessary attributes are present\n",
    "missing_mvp_attributes = [attr for attr in mvp_attributes if attr not in dominant_team_players.columns]\n",
    "if missing_mvp_attributes:\n",
    "    print(f\"Warning: The following MVP attributes are missing for {dominant_team}: {missing_mvp_attributes}\")\n",
    "\n",
    "# Predict MVP only for the dominant team using available attributes\n",
    "mvp_prediction = mvp_model.predict(dominant_team_players[available_mvp_attributes])\n",
    "print(f\"Predicted MVP from {dominant_team}: {mvp_prediction}\")\n",
    "\n",
    "# Injury Prediction for the dominant team\n",
    "# Ensure only available injury attributes are used\n",
    "available_injury_attributes = [attr for attr in injury_attributes if attr in dominant_team_players.columns]\n",
    "\n",
    "# Check for missing injury attributes\n",
    "missing_injury_attributes = [attr for attr in injury_attributes if attr not in dominant_team_players.columns]\n",
    "if missing_injury_attributes:\n",
    "    print(f\"Warning: The following injury attributes are missing for {dominant_team}: {missing_injury_attributes}\")\n",
    "\n",
    "# Predict injury likelihood for players in the dominant team\n",
    "injury_likelihood = injury_model.predict(dominant_team_players[available_injury_attributes])\n",
    "print(f\"Injury Likelihood for {dominant_team} players: {injury_likelihood}\")\n",
    "\n",
    "# Reshape dominant team stats to match the input format of the model\n",
    "# Ensure feature names match during prediction\n",
    "def prepare_team_stats_for_prediction(team_a_players, team_b_players):\n",
    "    # Aggregate stats for both teams\n",
    "    team_a_stats = aggregate_team_stats(team_a_players).add_suffix('_a')\n",
    "    team_b_stats = aggregate_team_stats(team_b_players).add_suffix('_b')\n",
    "    \n",
    "    # Combine both teams' stats into a single row\n",
    "    match_features = pd.concat([team_a_stats, team_b_stats], axis=0).to_frame().T\n",
    "    \n",
    "    # Ensure the order and names of columns match those used during training\n",
    "    expected_columns = X_train.columns  # The feature names used during model training\n",
    "    match_features = match_features.reindex(columns=expected_columns, fill_value=0)\n",
    "    \n",
    "    return match_features\n",
    "\n",
    "# Use the function before predicting\n",
    "dominant_team_stats = prepare_team_stats_for_prediction(team_a_players, team_b_players)\n",
    "\n",
    "# Predict the number of goals for the dominant team\n",
    "predicted_goals = goal_model.predict(dominant_team_stats)\n",
    "\n",
    "\n",
    "print(f\"Predicted number of goals for {dominant_team}: {round(predicted_goals[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install shap\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
